# Model Training Pipeline - MÃ´ Táº£ Chi Tiáº¿t ToÃ n Bá»™ Luá»“ng

## ðŸ“‹ Má»¥c Lá»¥c
1. [Tá»•ng Quan Kiáº¿n TrÃºc](#tá»•ng-quan-kiáº¿n-trÃºc)
2. [Phase 1: Import & Fetch](#phase-1-import--fetch)
3. [Phase 2: Ingestion](#phase-2-ingestion)
4. [Phase 3: Processing & Feature Extraction](#phase-3-processing--feature-extraction)
5. [Phase 4: Prediction](#phase-4-prediction)
6. [Entities & Data Model](#entities--data-model)
7. [API Endpoints](#api-endpoints)
8. [Frontend UI Flow](#frontend-ui-flow)
9. [Error Handling & Recovery](#error-handling--recovery)
10. [WebSocket Real-time Updates](#websocket-real-time-updates)

---

## Tá»•ng Quan Kiáº¿n TrÃºc

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MODEL TRAINING PIPELINE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Imports GitHub Repository
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: IMPORT & FETCH                 â”‚
â”‚  âœ“ Verify repo exists on GitHub          â”‚
â”‚  âœ“ Create ModelRepoConfig                â”‚
â”‚  âœ“ Fetch builds from CI API              â”‚
â”‚  âœ“ Create RawBuildRun records            â”‚
â”‚  âœ“ Create ModelImportBuild records       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: INGESTION                      â”‚
â”‚  âœ“ Clone/update git repositories         â”‚
â”‚  âœ“ Create git worktrees cho commits      â”‚
â”‚  âœ“ Download build logs tá»« CI             â”‚
â”‚  âœ“ Per-resource status tracking          â”‚
â”‚  âœ“ Mark builds as INGESTED/FAILED        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (User triggers manually)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: PROCESSING                     â”‚
â”‚  âœ“ Create ModelTrainingBuild records     â”‚
â”‚  âœ“ Extract features (Hamilton DAG)       â”‚
â”‚  âœ“ Store features in FeatureVector       â”‚
â”‚  âœ“ Sequential processing (temporal deps) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: PREDICTION                     â”‚
â”‚  âœ“ Batch prediction (parallel)           â”‚
â”‚  âœ“ Risk level classification             â”‚
â”‚  âœ“ Uncertainty estimation                â”‚
â”‚  âœ“ Store prediction results              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
ModelRepoConfig (PROCESSED) + Predictions Ready
```

### Queue Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Celery Queue System             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ processing   â”‚ Orchestration, feature  â”‚
â”‚              â”‚ extraction              â”‚
â”‚ ingestion    â”‚ Clone, worktree, logs   â”‚
â”‚ prediction   â”‚ ML model predictions    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Status Flow

```
ModelRepoConfig Status Flow:

    QUEUED â”€â”€â”€â”€â”€â”€â–º FETCHING â”€â”€â”€â”€â”€â”€â–º INGESTING â”€â”€â”€â”€â”€â”€â–º INGESTED
                      â”‚                  â”‚                â”‚
                      â–¼                  â–¼                â”‚
                   FAILED â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FAILED             â”‚
                      â”‚                                   â”‚
                      â–¼                                   â–¼
                 (Retry available)          (User triggers processing)
                                                          â”‚
                                                          â–¼
                                               â”Œâ”€â”€â”€ PROCESSING â”€â”€â”€â”
                                               â”‚                  â”‚
                                               â–¼                  â–¼
                                           PROCESSED           FAILED
                                               â”‚
                                               â–¼
                                     (Retry / Re-sync available)
```

---

## Phase 1: Import & Fetch

**Files**: 
- [backend/app/api/model_repos.py](backend/app/api/model_repos.py)
- [backend/app/services/model_repository_service.py](backend/app/services/model_repository_service.py)
- [backend/app/tasks/model_ingestion.py](backend/app/tasks/model_ingestion.py)

**Má»¥c Ä‘Ã­ch**: Import repository tá»« GitHub vÃ  fetch builds tá»« CI provider

### 1.1 Tasks Overview

| Task | Queue | Timeout | MÃ´ Táº£ |
|------|-------|---------|-------|
| `start_model_processing` | processing | 180s | Orchestrator: Báº¯t Ä‘áº§u toÃ n bá»™ pipeline |
| `ingest_model_builds` | ingestion | 180s | Dispatch fetch tasks (parallel or sequential) |
| `fetch_builds_batch` | ingestion | 360s | Fetch má»™t page builds tá»« CI API |
| `fetch_builds_until_existing` | ingestion | 900s | Sequential fetch cho sync mode |
| `aggregate_fetch_results` | ingestion | 120s | Aggregate fetch results (chord callback) |

### 1.2 Import Flow Diagram

```
User clicks "Import Repository"
       â”‚
       â–¼
bulk_import_repositories (API)
â”‚
â”œâ”€ Verify repo on GitHub API
â”œâ”€ Create/Update RawRepository
â”œâ”€ Create ModelRepoConfig (status=QUEUED)
â””â”€ Dispatch start_model_processing
       â”‚
       â–¼
start_model_processing (Celery)
â”‚
â”œâ”€ Update status â†’ INGESTING
â”œâ”€ Publish WebSocket event
â””â”€ Dispatch ingest_model_builds
       â”‚
       â–¼
ingest_model_builds
â”‚
â”œâ”€ Mode 1: sync_until_existing=True
â”‚   â””â”€ fetch_builds_until_existing (sequential)
â”‚       â”œâ”€ Fetch page, check if exists in DB
â”‚       â”œâ”€ Stop when hitting existing build
â”‚       â””â”€ Dispatch dispatch_ingestion
â”‚
â””â”€ Mode 2: Parallel fetch (chord pattern)
    â””â”€ chord(
           group(fetch_builds_batch Ã— N pages),
           aggregate_fetch_results
       )
       â””â”€ Dispatch dispatch_ingestion
```

### 1.3 Fetch Builds Logic

```python
# Tá»« fetch_builds_batch
fetch_kwargs = {
    "since": since_dt,          # Only builds after this date
    "limit": batch_size,        # Builds per page (default: 100)
    "page": page,               # Pagination
    "exclude_bots": True,       # Skip bot commits
    "only_with_logs": False,    # Optional: only if logs available
    "only_completed": True,     # Only completed builds
}

# Build filters applied:
# - status == COMPLETED
# - conclusion NOT IN (SKIPPED, ACTION_REQUIRED, STALE)
# - build_id is not null
```

### 1.4 Data Structures Created (Phase 1)

**RawRepository** (tá»« GitHub API):
```python
{
    full_name: "owner/repo",
    github_repo_id: int,
    default_branch: str,
    is_private: bool,
    main_lang: str,
    github_metadata: dict,
}
```

**RawBuildRun** (tá»« CI API):
```python
{
    raw_repo_id: ObjectId,
    ci_run_id: str,            # Unique build ID from CI
    build_id: str,             # CI provider build identifier
    provider: str,             # "github_actions", "circleci", etc.
    build_number: int,
    branch: str,
    commit_sha: str,
    commit_message: str,
    commit_author: str,
    status: BuildStatus,
    conclusion: BuildConclusion,
    created_at: datetime,
    duration_seconds: int,
    logs_available: bool,
}
```

**ModelImportBuild** (tracking record):
```python
{
    model_repo_config_id: ObjectId,
    raw_build_run_id: ObjectId,
    status: ModelImportBuildStatus,  # PENDING â†’ FETCHED â†’ INGESTING â†’ INGESTED
    ci_run_id: str,
    commit_sha: str,
    resource_status: {               # Per-resource tracking
        "git_history": ResourceStatusEntry,
        "git_worktree": ResourceStatusEntry,
        "build_logs": ResourceStatusEntry,
    },
    required_resources: List[str],
}
```

---

## Phase 2: Ingestion

**File**: [backend/app/tasks/model_ingestion.py](backend/app/tasks/model_ingestion.py)

**Má»¥c Ä‘Ã­ch**: Chuáº©n bá»‹ resources cáº§n thiáº¿t cho feature extraction

### 2.1 Tasks Overview

| Task | Queue | Timeout | Retries | MÃ´ Táº£ |
|------|-------|---------|---------|-------|
| `dispatch_ingestion` | ingestion | 180s | N/A | Build vÃ  dispatch ingestion workflow |
| `aggregate_model_ingestion_results` | ingestion | 60s | N/A | Aggregate results, mark builds INGESTED |
| `handle_ingestion_chord_error` | ingestion | 120s | N/A | Error handler cho chord failure |
| `reingest_failed_builds` | ingestion | 900s | N/A | Retry FAILED builds (not MISSING_RESOURCE) |

### 2.2 Resource DAG

Resources Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh tá»« template "Risk Prediction":

```
clone_repo (git bare clone)
    â”‚
    â”œâ”€â”€ create_worktree (per commit, sequential chunks)
    â”‚
    â””â”€â”€ download_build_logs (parallel, independent)
```

**Required Resources tá»« Template**:
```python
required_resources = template_service.get_required_resources_for_template("Risk Prediction")
# CÃ³ thá»ƒ bao gá»“m:
# - FeatureResource.GIT_HISTORY (clone)
# - FeatureResource.GIT_WORKTREE (worktree per commit)
# - FeatureResource.BUILD_LOGS (CI logs)
```

### 2.3 Ingestion Flow

```
dispatch_ingestion
â”‚
â”œâ”€ Mark all FETCHED builds as INGESTING
â”œâ”€ Get required resources from template
â”œâ”€ Initialize resource_status for each build
â”‚
â””â”€ chord(
       build_ingestion_workflow(
           clone_repo â†’ create_worktree_chunks â†’ download_logs_chunks
       ),
       aggregate_model_ingestion_results
   )
       â”‚
       â–¼
aggregate_model_ingestion_results
â”‚
â”œâ”€ Parse results from Redis / task arguments
â”œâ”€ Update per-resource status:
â”‚   â”œâ”€ git_history: COMPLETED/FAILED (affects ALL builds)
â”‚   â”œâ”€ git_worktree: Per-commit status
â”‚   â””â”€ build_logs: Per-build status
â”‚
â”œâ”€ Determine per-build final status:
â”‚   â”œâ”€ INGESTED: All resources ready
â”‚   â”œâ”€ FAILED: Actual error (timeout, network) - RETRYABLE
â”‚   â””â”€ MISSING_RESOURCE: Expected (logs expired) - NOT RETRYABLE
â”‚
â””â”€ Update ModelRepoConfig â†’ status=INGESTED
```

### 2.4 Resource Status Tracking

```python
class ResourceStatus(str, Enum):
    PENDING = "pending"       # Not started
    IN_PROGRESS = "in_progress"  # Currently fetching
    COMPLETED = "completed"   # Successfully completed
    FAILED = "failed"         # Failed with error
    SKIPPED = "skipped"       # Not required by template

class ResourceStatusEntry(BaseModel):
    status: ResourceStatus
    error: Optional[str]
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
```

### 2.5 ModelImportBuild Status Flow

```
    PENDING â”€â”€â”€â–º FETCHED â”€â”€â”€â–º INGESTING â”€â”€â”€â–º INGESTED
                                   â”‚              â”‚
                                   â–¼              â–¼
                              FAILED       (Ready for Processing)
                                   â”‚
                                   â–¼
                         MISSING_RESOURCE
                         (Not retryable)
```

---

## Phase 3: Processing & Feature Extraction

**File**: [backend/app/tasks/model_processing.py](backend/app/tasks/model_processing.py)

**Má»¥c Ä‘Ã­ch**: Extract features tá»« resources vÃ  lÆ°u vÃ o FeatureVector

### 3.1 Tasks Overview

| Task | Queue | Timeout | MÃ´ Táº£ |
|------|-------|---------|-------|
| `start_processing_phase` | processing | 120s | User triggers Phase 2, find pending builds |
| `dispatch_build_processing` | processing | 360s | Create ModelTrainingBuild, dispatch chain |
| `process_workflow_run` | processing | 900s | Extract features cho 1 build |
| `finalize_model_processing` | processing | 120s | Aggregate results, dispatch predictions |
| `retry_failed_builds` | processing | 360s | Retry FAILED builds |
| `handle_processing_chain_error` | processing | 120s | Error handler for chain failures |

### 3.2 Processing Flow

```
User clicks "Start Processing"
       â”‚
       â–¼
start_processing_phase (API â†’ Task)
â”‚
â”œâ”€ Check status is INGESTED or PROCESSED
â”œâ”€ Get checkpoint (last_processed_import_build_id)
â”œâ”€ Find unprocessed builds after checkpoint
â”‚   â””â”€ Include both INGESTED and FAILED builds
â””â”€ Dispatch dispatch_build_processing
       â”‚
       â–¼
dispatch_build_processing
â”‚
â”œâ”€ Create ModelTrainingBuild for each build (PENDING)
â”‚   â””â”€ Sorted by created_at (oldest â†’ newest)
â”‚
â”œâ”€ Update status â†’ PROCESSING
â”‚
â””â”€ chain(
       process_workflow_run(build_1),
       process_workflow_run(build_2),
       ...
       process_workflow_run(build_N),
       finalize_model_processing
   ).on_error(handle_processing_chain_error)
       â”‚
       â–¼
process_workflow_run (sequential for each build)
â”‚
â”œâ”€ Find ModelTrainingBuild (PENDING)
â”œâ”€ Mark extraction_status â†’ IN_PROGRESS
â”œâ”€ Get feature template (Risk Prediction)
â”‚
â”œâ”€ extract_features_for_build (Hamilton DAG)
â”‚   â”œâ”€ Git features (commits, diff, blame)
â”‚   â”œâ”€ Build log features (keywords, patterns)
â”‚   â”œâ”€ Temporal features (tr_prev_build)
â”‚   â””â”€ Store in FeatureVector
â”‚
â”œâ”€ Update ModelTrainingBuild:
â”‚   â”œâ”€ feature_vector_id
â”‚   â”œâ”€ extraction_status: COMPLETED/PARTIAL/FAILED
â”‚   â””â”€ extraction_error (if any)
â”‚
â”œâ”€ Track result in Redis (ProcessingTracker)
â””â”€ Publish WebSocket update
       â”‚
       â–¼
finalize_model_processing
â”‚
â”œâ”€ Get results from Redis tracker
â”œâ”€ Update repo_config:
â”‚   â”œâ”€ status â†’ PROCESSED
â”‚   â”œâ”€ last_processed_import_build_id (checkpoint)
â”‚   â””â”€ builds_processing_failed count
â”‚
â””â”€ Dispatch predict_builds_batch (parallel batches)
```

### 3.3 Sequential Processing Pattern

Processing PHáº¢I tuáº§n tá»± (oldest â†’ newest) vÃ¬:

```python
# Temporal features depend on previous builds
# VÃ­ dá»¥: tr_prev_build_duration, tr_success_rate_last_5

# Build chain pattern:
chain(
    process_workflow_run(build_1),  # 2024-01-01
    process_workflow_run(build_2),  # 2024-01-02 (references build_1)
    process_workflow_run(build_3),  # 2024-01-03 (references build_2)
    ...
    finalize_model_processing
)
```

### 3.4 Checkpoint Mechanism

```python
# Trong start_processing_phase:
last_checkpoint_id = repo_config.last_processed_import_build_id

# Find builds AFTER checkpoint
pending_builds = import_build_repo.find_unprocessed_builds(
    repo_config_id,
    after_id=last_checkpoint_id,  # ObjectId comparison
    include_failed=True
)

# Sau khi processing hoÃ n thÃ nh (finalize):
update_data["last_processed_import_build_id"] = ObjectId(last_build_id)
```

### 3.5 Data Structures Created (Phase 3)

**ModelTrainingBuild**:
```python
{
    raw_repo_id: ObjectId,
    raw_build_run_id: ObjectId,
    model_repo_config_id: ObjectId,
    model_import_build_id: ObjectId,
    
    # Feature storage reference
    feature_vector_id: ObjectId,  # â†’ FeatureVector collection
    
    # Denormalized metadata
    head_sha: str,
    build_number: int,
    build_created_at: datetime,
    
    # Extraction status
    extraction_status: ExtractionStatus,  # PENDING â†’ IN_PROGRESS â†’ COMPLETED
    extraction_error: Optional[str],
    extracted_at: Optional[datetime],
    
    # Prediction results (Phase 4)
    prediction_status: ExtractionStatus,
    predicted_label: str,           # "LOW", "MEDIUM", "HIGH"
    prediction_confidence: float,   # 0-1
    prediction_uncertainty: float,
    prediction_model_version: str,
    predicted_at: datetime,
}
```

**FeatureVector** (single source of truth for features):
```python
{
    raw_repo_id: ObjectId,
    raw_build_run_id: ObjectId,
    ci_run_id: str,
    
    # Computed features
    features: {
        "git_commit_count": 5,
        "git_diff_lines_added": 120,
        "git_diff_lines_deleted": 45,
        "build_log_error_count": 2,
        "tr_prev_build_duration": 180.5,
        ...
    },
    
    # Normalized features (for prediction)
    normalized_features: {...},
    
    # Temporal linking
    tr_prev_build: Optional[str],  # Previous build's ci_run_id
}
```

---

## Phase 4: Prediction

**File**: [backend/app/tasks/model_processing.py](backend/app/tasks/model_processing.py)

**Má»¥c Ä‘Ã­ch**: Dá»± Ä‘oÃ¡n risk level cho má»—i build

### 4.1 Prediction Task

| Task | Queue | Timeout | MÃ´ Táº£ |
|------|-------|---------|-------|
| `predict_builds_batch` | prediction | 360s | Batch prediction cho nhiá»u builds |

### 4.2 Prediction Flow

```
finalize_model_processing
â”‚
â””â”€ Dispatch prediction batches
       â”‚
       â–¼
predict_builds_batch (parallel batches)
â”‚
â”œâ”€ For each build_id in batch:
â”‚   â”œâ”€ Get ModelTrainingBuild
â”‚   â”œâ”€ Get FeatureVector (features)
â”‚   â”œâ”€ Walk temporal chain (5 previous builds)
â”‚   â””â”€ Add to prediction queue
â”‚
â”œâ”€ Mark all as prediction_status â†’ IN_PROGRESS
â”‚
â”œâ”€ Normalize features (PredictionService.normalize_features)
â”‚   â””â”€ Save normalized_features to FeatureVector
â”‚
â”œâ”€ Run batch prediction:
â”‚   â”œâ”€ LSTM temporal model (if history available)
â”‚   â””â”€ Fallback to simple classifier
â”‚
â””â”€ Update each ModelTrainingBuild:
    â”œâ”€ predicted_label: "LOW" | "MEDIUM" | "HIGH"
    â”œâ”€ prediction_confidence: 0.0 - 1.0
    â”œâ”€ prediction_uncertainty: Bayesian uncertainty
    â””â”€ prediction_status: COMPLETED | FAILED
```

### 4.3 Prediction Result Structure

```python
class PredictionResult:
    risk_level: str      # "LOW", "MEDIUM", "HIGH"
    risk_score: float    # Confidence score (0-1)
    uncertainty: float   # Bayesian uncertainty
    model_version: str   # Model version used
    error: Optional[str] # Error message if failed
```

---

## Entities & Data Model

### Entity Relationship Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RawRepository     â”‚     â”‚    RawBuildRun      â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ _id                 â”‚â—„â”€â”€â”€â”€â”¤ raw_repo_id         â”‚
â”‚ full_name           â”‚     â”‚ _id                 â”‚
â”‚ github_repo_id      â”‚     â”‚ ci_run_id           â”‚
â”‚ default_branch      â”‚     â”‚ commit_sha          â”‚
â”‚ is_private          â”‚     â”‚ build_number        â”‚
â”‚ main_lang           â”‚     â”‚ status              â”‚
â”‚ ci_provider         â”‚     â”‚ conclusion          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                            â”‚
         â”‚                            â”‚
         â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ModelRepoConfig    â”‚     â”‚  ModelImportBuild   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ _id                 â”‚â—„â”€â”€â”€â”€â”¤ model_repo_config_idâ”‚
â”‚ raw_repo_id         â”‚     â”‚ raw_build_run_id    â”‚â”€â”€â”€â”€â”
â”‚ user_id             â”‚     â”‚ status              â”‚    â”‚
â”‚ full_name           â”‚     â”‚ resource_status     â”‚    â”‚
â”‚ ci_provider         â”‚     â”‚ ci_run_id           â”‚    â”‚
â”‚ status              â”‚     â”‚ commit_sha          â”‚    â”‚
â”‚ max_builds_to_ingestâ”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚ since_days          â”‚                                â”‚
â”‚ builds_fetched      â”‚                                â”‚
â”‚ builds_ingested     â”‚                                â”‚
â”‚ builds_completed    â”‚                                â”‚
â”‚ last_processed_id   â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
         â”‚                                             â”‚
         â”‚                                             â”‚
         â–¼                                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ ModelTrainingBuild  â”‚     â”‚   FeatureVector     â”‚    â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚
â”‚ _id                 â”‚     â”‚ _id                 â”‚    â”‚
â”‚ model_repo_config_idâ”‚     â”‚ raw_repo_id         â”‚    â”‚
â”‚ model_import_build_id     â”‚ raw_build_run_id    â”‚â—„â”€â”€â”€â”˜
â”‚ raw_repo_id         â”‚     â”‚ ci_run_id           â”‚
â”‚ raw_build_run_id    â”‚     â”‚ features            â”‚
â”‚ feature_vector_id   â”‚â”€â”€â”€â”€â–ºâ”‚ normalized_features â”‚
â”‚ extraction_status   â”‚     â”‚ tr_prev_build       â”‚
â”‚ prediction_status   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ predicted_label     â”‚
â”‚ prediction_confidenceâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Status Enums

```python
class ModelImportStatus(str, Enum):
    """ModelRepoConfig status"""
    QUEUED = "queued"
    FETCHING = "fetching"
    INGESTING = "ingesting"
    INGESTED = "ingested"
    PROCESSING = "processing"
    PROCESSED = "processed"
    FAILED = "failed"

class ModelImportBuildStatus(str, Enum):
    """ModelImportBuild status (ingestion phase)"""
    PENDING = "pending"
    FETCHED = "fetched"
    INGESTING = "ingesting"
    INGESTED = "ingested"
    MISSING_RESOURCE = "missing_resource"  # Not retryable
    FAILED = "failed"                       # Retryable

class ExtractionStatus(str, Enum):
    """ModelTrainingBuild extraction/prediction status"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    PARTIAL = "partial"
    FAILED = "failed"
```

---

## API Endpoints

**File**: [backend/app/api/model_repos.py](backend/app/api/model_repos.py)

### Repository Management

| Method | Endpoint | MÃ´ Táº£ |
|--------|----------|-------|
| `POST` | `/repos/import/bulk` | Import multiple repositories |
| `GET` | `/repos/` | List repositories |
| `GET` | `/repos/search` | Search repositories |
| `GET` | `/repos/{repo_id}` | Get repository detail |
| `DELETE` | `/repos/{repo_id}` | Delete repository (cascade) |

### Pipeline Control

| Method | Endpoint | MÃ´ Táº£ |
|--------|----------|-------|
| `POST` | `/repos/{repo_id}/sync-run` | Trigger manual sync (fetch new builds) |
| `POST` | `/repos/{repo_id}/start-processing` | Start Phase 2 (processing) |
| `POST` | `/repos/{repo_id}/reingest-failed` | Retry failed ingestion |
| `POST` | `/repos/{repo_id}/reprocess-failed` | Retry failed processing |
| `POST` | `/repos/{repo_id}/retry-predictions` | Retry failed predictions |

### Progress & Builds

| Method | Endpoint | MÃ´ Táº£ |
|--------|----------|-------|
| `GET` | `/repos/{repo_id}/import-progress` | Get detailed import progress |
| `GET` | `/repos/{repo_id}/import-builds` | List ModelImportBuild records |
| `GET` | `/repos/{repo_id}/training-builds` | List ModelTrainingBuild records |
| `GET` | `/repos/{repo_id}/builds` | List builds (RawBuildRun enriched) |
| `GET` | `/repos/{repo_id}/builds/{build_id}` | Get build detail |

### Export

| Method | Endpoint | MÃ´ Táº£ |
|--------|----------|-------|
| `GET` | `/repos/{repo_id}/export/preview` | Preview exportable data |
| `GET` | `/repos/{repo_id}/export` | Stream export (CSV/JSON) |
| `POST` | `/repos/{repo_id}/export/async` | Create async export job |

---

## Frontend UI Flow

**Files**: [frontend/src/app/(app)/repositories/](frontend/src/app/(app)/repositories/)

### Page Structure

```
/repositories
â”œâ”€â”€ page.tsx              # Repository list
â”œâ”€â”€ import/
â”‚   â””â”€â”€ page.tsx          # Import wizard (2 steps)
â””â”€â”€ [repoId]/
    â”œâ”€â”€ layout.tsx        # Repo context & tabs
    â”œâ”€â”€ page.tsx          # Redirect to overview
    â”œâ”€â”€ overview/
    â”‚   â””â”€â”€ page.tsx      # Pipeline overview
    â”œâ”€â”€ builds/
    â”‚   â”œâ”€â”€ page.tsx      # Builds list
    â”‚   â”œâ”€â”€ ingestion/
    â”‚   â”‚   â””â”€â”€ page.tsx  # Ingestion builds table
    â”‚   â”œâ”€â”€ processing/
    â”‚   â”‚   â””â”€â”€ page.tsx  # Processing builds table
    â”‚   â””â”€â”€ [buildId]/
    â”‚       â””â”€â”€ page.tsx  # Build detail
    â””â”€â”€ _tabs/
        â”œâ”€â”€ OverviewTab.tsx
        â”œâ”€â”€ BuildsTab.tsx
        â””â”€â”€ IssuesTab.tsx
```

### Import Flow UI

```
Step 1: Select Repositories
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Search: [_________________________] ðŸ”                  â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚ Private Repositories          â”‚  Selected (3)               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â˜ org/private-repo-1      â”‚ â”‚ â”‚ âœ“ org/selected-repo-1   â”‚ â”‚
â”‚ â”‚ â˜‘ org/private-repo-2      â”‚ â”‚ â”‚ âœ“ org/selected-repo-2   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ âœ“ user/public-repo-1    â”‚ â”‚
â”‚                               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ Public Repositories           â”‚                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                             â”‚
â”‚ â”‚ â˜‘ user/public-repo-1      â”‚ â”‚                             â”‚
â”‚ â”‚ â˜ user/public-repo-2      â”‚ â”‚                             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                             â”‚
â”‚                                                              â”‚
â”‚                                               [Back] [Next â†’]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Configure & Import
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Repository Configuration      â”‚  Feature Extraction Plan    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ org/selected-repo-1       â”‚ â”‚ â”‚ Template: Risk Predict  â”‚ â”‚
â”‚ â”‚ CI: [GitHub Actions â–¼]    â”‚ â”‚ â”‚                         â”‚ â”‚
â”‚ â”‚ Max builds: [100    ]     â”‚ â”‚ â”‚ Features:               â”‚ â”‚
â”‚ â”‚ Since days: [90     ]     â”‚ â”‚ â”‚ â”œâ”€ git_commit_count     â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚ â”œâ”€ git_diff_lines       â”‚ â”‚
â”‚ â”‚ org/selected-repo-2       â”‚ â”‚ â”‚ â”œâ”€ build_duration       â”‚ â”‚
â”‚ â”‚ CI: [GitHub Actions â–¼]    â”‚ â”‚ â”‚ â””â”€ ...                  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚                                    [â† Back] [Import 3 Repos] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Overview Tab Components

```
OverviewTab
â”œâ”€â”€ MiniStepper          # Phase indicator (Fetch â†’ Ingest â†’ Process)
â”œâ”€â”€ CurrentPhaseCard     # Active phase details (shown during progress)
â”œâ”€â”€ CollectionCard       # Ingestion stats & controls
â”‚   â”œâ”€â”€ Fetched count
â”‚   â”œâ”€â”€ Ingested count
â”‚   â”œâ”€â”€ Failed count
â”‚   â”œâ”€â”€ [Sync] button
â”‚   â””â”€â”€ [Retry Failed] button
â”œâ”€â”€ ProcessingCard       # Processing stats & controls
â”‚   â”œâ”€â”€ Extracted count
â”‚   â”œâ”€â”€ Predicted count
â”‚   â”œâ”€â”€ Failed count
â”‚   â”œâ”€â”€ [Start Processing] button
â”‚   â””â”€â”€ [Retry Failed] button
â””â”€â”€ Repository Info      # Branch, language, CI provider
```

---

## Error Handling & Recovery

### Ingestion Errors

| Error Type | Status | Retryable | Action |
|------------|--------|-----------|--------|
| Clone failed (timeout) | FAILED | Yes | `reingest_failed_builds` |
| Worktree creation failed | FAILED | Yes | `reingest_failed_builds` |
| Log download timeout | FAILED | Yes | `reingest_failed_builds` |
| Logs expired (404) | MISSING_RESOURCE | No | Cannot retry |
| Commit not in repo | MISSING_RESOURCE | No | Cannot retry |

### Processing Errors

| Error Type | Status | Retryable | Action |
|------------|--------|-----------|--------|
| Feature extraction failed | FAILED | Yes | `retry_failed_builds` |
| Hamilton DAG error | FAILED | Yes | `retry_failed_builds` |
| Prediction timeout | FAILED | Yes | `retry_predictions` |
| Prediction model error | FAILED | Yes | `retry_predictions` |

### Error Callbacks

```python
# Ingestion chord error
handle_ingestion_chord_error:
  - Mark all INGESTING â†’ FAILED
  - Update repo â†’ INGESTED (partial success) or FAILED
  - Allow user to retry

# Processing chain error
handle_processing_chain_error:
  - Mark all IN_PROGRESS â†’ FAILED
  - Update repo â†’ PROCESSED or FAILED
  - Allow user to retry
```

---

## WebSocket Real-time Updates

### Event Types

```python
# Repository status update
{
    "event": "REPO_UPDATE",
    "repo_id": "...",
    "status": "ingesting",
    "message": "Preparing resources for 50 builds...",
    "stats": {
        "builds_fetched": 100,
        "builds_ingested": 50,
        "builds_missing_resource": 5,
    }
}

# Build status update
{
    "event": "BUILD_UPDATE",
    "repo_id": "...",
    "build_id": "...",
    "status": "completed",
}
```

### Frontend Subscription

```tsx
// In layout.tsx
useEffect(() => {
    const unsubscribe = subscribe("REPO_UPDATE", (data: any) => {
        if (data.repo_id === repoId) {
            loadRepo();
            loadProgress();
            loadBuilds();
        }
    });
    return () => unsubscribe();
}, [subscribe, ...]);
```

---

## Performance Optimization

### Batch Processing

```python
# Fetch: Parallel pages vá»›i chord
chord(
    group(fetch_builds_batch Ã— N),
    aggregate_fetch_results
)

# Ingestion: Chunked parallel tasks
group([
    clone_repo,
    group(create_worktree_chunk Ã— M),
    group(download_logs_chunk Ã— K),
])

# Prediction: Parallel batches
PREDICTION_BUILDS_PER_BATCH = 50
group(predict_builds_batch Ã— ceil(N/50))
```

### Checkpoint-based Processing

```python
# Only process builds after checkpoint
pending_builds = import_build_repo.find_unprocessed_builds(
    repo_config_id,
    after_id=last_checkpoint_id,  # ObjectId comparison is efficient
)

# Checkpoint updated AFTER processing completes
# Prevents re-processing on retry
```

### Database Optimization

- **Indexes**: `raw_build_run_id + model_repo_config_id` compound index
- **Bulk operations**: `bulk_insert`, `update_many_by_status`
- **Atomic upserts**: `upsert_by_business_key` prevents duplicates
- **ObjectId cursors**: Efficient pagination without offset

---

## Summary

Model Training Pipeline lÃ  má»™t há»‡ thá»‘ng 4-phase xá»­ lÃ½ builds tá»« GitHub:

1. **Import & Fetch**: Verify repo, fetch builds tá»« CI API
2. **Ingestion**: Clone git, create worktrees, download logs
3. **Processing**: Extract features (sequential), store in FeatureVector
4. **Prediction**: Batch prediction vá»›i ML model

**Key Design Decisions**:
- Two-phase pipeline vá»›i user control (Ingestion â†’ Processing)
- Sequential processing cho temporal features
- Checkpoint mechanism cho incremental processing
- Graceful degradation (MISSING_RESOURCE vs FAILED)
- Real-time updates via WebSocket
