{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DuPWlqErM6G","outputId":"6985570d-3b06-494a-fa25-6d306bf64700","executionInfo":{"status":"ok","timestamp":1767254404458,"user_tz":-420,"elapsed":2602,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Running on Google Colab\n"]}],"source":["# Google Colab only\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","print(\"✅ Running on Google Colab\")\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a41cff4","outputId":"d2d258d0-e62c-46a9-dd7b-a93698dffd7f","executionInfo":{"status":"ok","timestamp":1767254404463,"user_tz":-420,"elapsed":6,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory set to: /content/drive/MyDrive/hunglt\n"]}],"source":["import os\n","\n","root_path = '/content/drive/MyDrive/hunglt'\n","\n","os.makedirs(root_path, exist_ok=True)\n","os.chdir(root_path)\n","\n","print(f\"Current working directory set to: {os.getcwd()}\")\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egxtIroS9X69","outputId":"8fb6d994-c93a-4067-9dc0-fa8c5b02cd4b","executionInfo":{"status":"ok","timestamp":1767254404473,"user_tz":-420,"elapsed":3,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CompletedProcess(args=['ls', '-la'], returncode=0)"]},"metadata":{},"execution_count":13}],"source":["import subprocess\n","subprocess.run(['ls', '-la'], check=True)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hHgkO6u--sQ","outputId":"493674ed-e482-4e6e-84b7-533819f3b7bc","executionInfo":{"status":"ok","timestamp":1767254404475,"user_tz":-420,"elapsed":2,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CompletedProcess(args=['ls', '-la', 'final_dataset/final_clean.csv'], returncode=0)"]},"metadata":{},"execution_count":14}],"source":["import subprocess\n","subprocess.run(['ls', '-la', 'final_dataset/final_clean.csv'], check=True)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"yNS35e7rEDvJ","outputId":"1a36b836-01de-4f5d-fdcb-7eb5845e50df","executionInfo":{"status":"ok","timestamp":1767254407513,"user_tz":-420,"elapsed":3037,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(357781, 70)\n","['tr_build_id', 'tr_original_commit', 'tr_build_number', 'gh_project_name', 'gh_is_pr', 'gh_lang', 'git_branch', 'git_prev_commit_resolution_status', 'git_prev_built_commit', 'tr_prev_build', 'gh_team_size', 'git_all_built_commits', 'git_num_all_built_commits', 'git_trigger_commit', 'gh_num_commit_comments', 'git_diff_src_churn', 'gh_diff_files_added', 'gh_diff_files_deleted', 'gh_diff_files_modified', 'gh_diff_tests_added', 'gh_diff_tests_deleted', 'gh_diff_src_files', 'gh_diff_doc_files', 'gh_diff_other_files', 'gh_num_commits_on_files_touched', 'gh_sloc', 'gh_test_lines_per_kloc', 'gh_test_cases_per_kloc', 'gh_asserts_cases_per_kloc', 'gh_by_core_team_member', 'gh_build_started_at', 'gh_repo_age', 'gh_repo_num_commits', 'tr_log_num_jobs', 'tr_log_tests_run_sum', 'tr_log_tests_failed_sum', 'tr_log_tests_skipped_sum', 'tr_log_tests_ok_sum', 'tr_log_testduration_sum', 'tr_log_tests_fail_rate', 'tr_log_analyzers_all', 'tr_log_frameworks_all', 'tr_log_lan_all', 'tr_duration', 'tr_status', 'tr_jobs', 'change_entropy', 'file_change_frequency', 'churn_ratio_vs_avg', 'prev_tr_status', 'is_prev_failed', 'prev_fail_streak', 'fail_rate_last_10', 'avg_src_churn_last_5', 'gh_has_bug_label', 'author_ownership', 'is_new_contributor', 'build_time_sin', 'build_time_cos', 'build_hour_risk_score', 'time_since_prev_build', 'commit_message_length', 'has_issue_reference', 'files_modified_ratio', 'is_merge_commit', 'days_since_last_author_commit', 'author_total_commits', 'risk_score', 'risk_label', 'risk_label_numeric']\n"]},{"output_type":"display_data","data":{"text/plain":["   tr_build_id                        tr_original_commit  tr_build_number  \\\n","0       223084  dfcbe784a598382625a2da337613da04b73785d5                1   \n","1       223084  dfcbe784a598382625a2da337613da04b73785d5                1   \n","2       223093  83ca85f58495cad524ec70198f9d422ff95ab3b4                2   \n","3       223093  83ca85f58495cad524ec70198f9d422ff95ab3b4                2   \n","4       223126  6df541d5b0c8339af0a3e894bb4aac7ca0b0a795                3   \n","\n","          gh_project_name  gh_is_pr gh_lang   git_branch  \\\n","0  AlchemyCMS/alchemy_cms         0    ruby       master   \n","1  AlchemyCMS/alchemy_cms         0    ruby       master   \n","2  AlchemyCMS/alchemy_cms         0    ruby  next_stable   \n","3  AlchemyCMS/alchemy_cms         0    ruby  next_stable   \n","4  AlchemyCMS/alchemy_cms         0    ruby  next_stable   \n","\n","  git_prev_commit_resolution_status                     git_prev_built_commit  \\\n","0                       merge_found                                       NaN   \n","1                       merge_found                                       NaN   \n","2                       merge_found                                       NaN   \n","3                       merge_found                                       NaN   \n","4                       build_found  83ca85f58495cad524ec70198f9d422ff95ab3b4   \n","\n","   tr_prev_build  ...  time_since_prev_build commit_message_length  \\\n","0     35685529.0  ...                    NaN                   0.0   \n","1     35685529.0  ...                    NaN                   0.0   \n","2     35685529.0  ...                    NaN                   0.0   \n","3     35685529.0  ...                    NaN                   0.0   \n","4       223093.0  ...               0.161111                   0.0   \n","\n","   has_issue_reference files_modified_ratio  is_merge_commit  \\\n","0                    0             0.838710                0   \n","1                    0             0.838710                0   \n","2                    0             0.777778                0   \n","3                    0             0.777778                0   \n","4                    0             1.000000                0   \n","\n","   days_since_last_author_commit  author_total_commits  risk_score  \\\n","0                            0.0                   0.0    0.019206   \n","1                            0.0                   0.0    0.019206   \n","2                            0.0                   0.0    0.034552   \n","3                            0.0                   0.0    0.034552   \n","4                            0.0                   0.0    0.034552   \n","\n","   risk_label  risk_label_numeric  \n","0      Medium                 1.0  \n","1      Medium                 1.0  \n","2        High                 2.0  \n","3        High                 2.0  \n","4        High                 2.0  \n","\n","[5 rows x 70 columns]"],"text/html":["\n","  <div id=\"df-18d599be-1c2a-447f-850d-9fcc9cd03147\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tr_build_id</th>\n","      <th>tr_original_commit</th>\n","      <th>tr_build_number</th>\n","      <th>gh_project_name</th>\n","      <th>gh_is_pr</th>\n","      <th>gh_lang</th>\n","      <th>git_branch</th>\n","      <th>git_prev_commit_resolution_status</th>\n","      <th>git_prev_built_commit</th>\n","      <th>tr_prev_build</th>\n","      <th>...</th>\n","      <th>time_since_prev_build</th>\n","      <th>commit_message_length</th>\n","      <th>has_issue_reference</th>\n","      <th>files_modified_ratio</th>\n","      <th>is_merge_commit</th>\n","      <th>days_since_last_author_commit</th>\n","      <th>author_total_commits</th>\n","      <th>risk_score</th>\n","      <th>risk_label</th>\n","      <th>risk_label_numeric</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>223084</td>\n","      <td>dfcbe784a598382625a2da337613da04b73785d5</td>\n","      <td>1</td>\n","      <td>AlchemyCMS/alchemy_cms</td>\n","      <td>0</td>\n","      <td>ruby</td>\n","      <td>master</td>\n","      <td>merge_found</td>\n","      <td>NaN</td>\n","      <td>35685529.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.838710</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.019206</td>\n","      <td>Medium</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>223084</td>\n","      <td>dfcbe784a598382625a2da337613da04b73785d5</td>\n","      <td>1</td>\n","      <td>AlchemyCMS/alchemy_cms</td>\n","      <td>0</td>\n","      <td>ruby</td>\n","      <td>master</td>\n","      <td>merge_found</td>\n","      <td>NaN</td>\n","      <td>35685529.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.838710</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.019206</td>\n","      <td>Medium</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>223093</td>\n","      <td>83ca85f58495cad524ec70198f9d422ff95ab3b4</td>\n","      <td>2</td>\n","      <td>AlchemyCMS/alchemy_cms</td>\n","      <td>0</td>\n","      <td>ruby</td>\n","      <td>next_stable</td>\n","      <td>merge_found</td>\n","      <td>NaN</td>\n","      <td>35685529.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.777778</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.034552</td>\n","      <td>High</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>223093</td>\n","      <td>83ca85f58495cad524ec70198f9d422ff95ab3b4</td>\n","      <td>2</td>\n","      <td>AlchemyCMS/alchemy_cms</td>\n","      <td>0</td>\n","      <td>ruby</td>\n","      <td>next_stable</td>\n","      <td>merge_found</td>\n","      <td>NaN</td>\n","      <td>35685529.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.777778</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.034552</td>\n","      <td>High</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>223126</td>\n","      <td>6df541d5b0c8339af0a3e894bb4aac7ca0b0a795</td>\n","      <td>3</td>\n","      <td>AlchemyCMS/alchemy_cms</td>\n","      <td>0</td>\n","      <td>ruby</td>\n","      <td>next_stable</td>\n","      <td>build_found</td>\n","      <td>83ca85f58495cad524ec70198f9d422ff95ab3b4</td>\n","      <td>223093.0</td>\n","      <td>...</td>\n","      <td>0.161111</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.034552</td>\n","      <td>High</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 70 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18d599be-1c2a-447f-850d-9fcc9cd03147')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-18d599be-1c2a-447f-850d-9fcc9cd03147 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-18d599be-1c2a-447f-850d-9fcc9cd03147');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-32095088-8d24-4a2d-8704-967959e230e2\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32095088-8d24-4a2d-8704-967959e230e2')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-32095088-8d24-4a2d-8704-967959e230e2 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}],"source":["# Load dữ liệu từ CSV\n","import pandas as pd\n","import numpy as np\n","import random\n","import torch\n","\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","DATA_PATH = \"./final_dataset/final_clean.csv\"\n","\n","df = pd.read_csv(DATA_PATH)\n","\n","print(df.shape)\n","print(df.columns.tolist())\n","\n","# Display the head of the DataFrame\n","display(df.head())\n","\n","# Cột phục vụ grouping/sort + chain\n","GROUP_COL = \"gh_project_name\"\n","TIME_COL = \"gh_build_started_at\"\n","BUILD_ID_COL = \"tr_build_id\"\n","PREV_BUILD_COL = \"tr_prev_build\"\n","LABEL_COL = \"risk_label_numeric\"\n","\n","# Temporal features (chuỗi build gần nhất)\n","TEMPORAL_FEATURES = [\n","    \"is_prev_failed\",\n","    \"prev_fail_streak\",\n","    \"fail_rate_last_10\",\n","    \"avg_src_churn_last_5\",\n","    \"time_since_prev_build\"\n","]\n","\n","# Static features (sau build, trước deploy)\n","STATIC_FEATURES = [\n","    \"git_diff_src_churn\",\n","    \"gh_diff_files_added\",\n","    \"gh_diff_files_deleted\",\n","    \"gh_diff_files_modified\",\n","    \"gh_diff_tests_added\",\n","    \"gh_diff_tests_deleted\",\n","    \"gh_diff_src_files\",\n","    \"gh_diff_doc_files\",\n","    \"gh_diff_other_files\",\n","    \"gh_num_commits_on_files_touched\",\n","    \"files_modified_ratio\",\n","    \"change_entropy\",\n","    \"churn_ratio_vs_avg\",\n","    \"gh_sloc\",\n","    \"gh_repo_age\",\n","    \"gh_repo_num_commits\",\n","    \"gh_test_lines_per_kloc\",\n","    \"gh_test_cases_per_kloc\",\n","    \"gh_asserts_cases_per_kloc\",\n","    \"gh_team_size\",\n","    \"author_ownership\",\n","    \"is_new_contributor\",\n","    \"days_since_last_author_commit\",\n","    \"tr_log_num_jobs\",\n","    \"tr_log_tests_run_sum\",\n","    \"tr_log_tests_failed_sum\",\n","    \"tr_log_tests_skipped_sum\",\n","    \"tr_log_tests_ok_sum\",\n","    \"tr_log_testduration_sum\",\n","    \"tr_log_tests_fail_rate\",\n","    \"tr_duration\",\n","    \"tr_status_num\",\n","    \"build_time_sin\",\n","    \"build_time_cos\",\n","    \"build_hour_risk_score\"\n","]\n","\n","LOG1P_FEATURES = [\n","    \"git_diff_src_churn\",\n","    \"gh_diff_files_added\",\n","    \"gh_diff_files_deleted\",\n","    \"gh_diff_files_modified\",\n","    \"gh_diff_tests_added\",\n","    \"gh_diff_tests_deleted\",\n","    \"gh_diff_src_files\",\n","    \"gh_diff_doc_files\",\n","    \"gh_diff_other_files\",\n","    \"gh_num_commits_on_files_touched\",\n","    \"gh_sloc\",\n","    \"gh_repo_age\",\n","    \"gh_repo_num_commits\",\n","    \"tr_log_num_jobs\",\n","    \"tr_log_tests_run_sum\",\n","    \"tr_log_tests_failed_sum\",\n","    \"tr_log_tests_skipped_sum\",\n","    \"tr_log_tests_ok_sum\",\n","    \"tr_log_testduration_sum\",\n","    \"tr_duration\",\n","    \"time_since_prev_build\",\n","    \"days_since_last_author_commit\"\n","]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"eMQ7HxuWFbnT","executionInfo":{"status":"ok","timestamp":1767254407523,"user_tz":-420,"elapsed":4,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[],"source":["# Dataset cho LSTM (sequence theo tr_prev_build)\n","import torch\n","from torch.utils.data import Dataset\n","\n","def build_sequences_from_prev(df, seq_len, min_seq_len=1):\n","    build_ids = df[BUILD_ID_COL].to_numpy()\n","    prev_ids = df[PREV_BUILD_COL].to_numpy()\n","    group_vals = df[GROUP_COL].to_numpy()\n","\n","    id_to_idx = {}\n","    for idx, build_id in enumerate(build_ids):\n","        if build_id == -1:\n","            continue\n","        id_to_idx[build_id] = idx\n","\n","    sequences = []\n","    for idx in range(len(df)):\n","        prev_id = prev_ids[idx]\n","        seq = []\n","        visited = set()\n","\n","        while len(seq) < seq_len and prev_id != -1:\n","            if prev_id in visited:\n","                break\n","            visited.add(prev_id)\n","\n","            prev_idx = id_to_idx.get(prev_id)\n","            if prev_idx is None:\n","                break\n","            if group_vals[prev_idx] != group_vals[idx]:\n","                break\n","\n","            seq.append(prev_idx)\n","            prev_id = prev_ids[prev_idx]\n","\n","        if len(seq) >= min_seq_len:\n","            seq = seq[::-1]\n","            sequences.append((seq, idx, len(seq)))\n","\n","    return sequences\n","\n","class BuildSequenceDataset(Dataset):\n","    def __init__(self, df, sequences):\n","        self.df = df\n","        self.sequences = sequences\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        seq_indices, label_idx, seq_len = self.sequences[idx]\n","        seq = self.df.iloc[seq_indices][TEMPORAL_FEATURES].to_numpy(dtype=np.float32)\n","        static = self.df.iloc[label_idx][STATIC_FEATURES].to_numpy(dtype=np.float32)\n","        label = int(self.df.iloc[label_idx][LABEL_COL])\n","        if seq_len < SEQ_LEN:\n","            pad = np.zeros((SEQ_LEN - seq_len, seq.shape[1]), dtype=np.float32)\n","            seq = np.concatenate([seq, pad], axis=0)\n","\n","        return (\n","            torch.from_numpy(seq),\n","            torch.from_numpy(static),\n","            torch.tensor(label, dtype=torch.long),\n","            torch.tensor(seq_len, dtype=torch.long)\n","        )\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywrTq6WODwBP","outputId":"a1d3471c-6c85-4118-aed5-aa8cf0a1ea28","executionInfo":{"status":"ok","timestamp":1767254417516,"user_tz":-420,"elapsed":9992,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3970574989.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.68768469 -0.68768469 -0.68768469 ... -0.55491594 -0.55491594\n"," -0.55491594]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.loc[:, STATIC_FEATURES] = scaler_static.transform(df[STATIC_FEATURES])\n","/tmp/ipython-input-3970574989.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.08421638 -0.08421638 -0.08421638 ... -0.08421638 -0.08421638\n"," -0.08421638]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.loc[:, STATIC_FEATURES] = scaler_static.transform(df[STATIC_FEATURES])\n","/tmp/ipython-input-3970574989.py:69: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.54876769 -0.54876769  1.82226472 ... -0.54876769 -0.54876769\n"," -0.54876769]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.loc[:, STATIC_FEATURES] = scaler_static.transform(df[STATIC_FEATURES])\n","/tmp/ipython-input-3970574989.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.44901299 -0.44901299 -0.44901299 ... -0.44901299 -0.44901299\n"," -0.44901299]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n","  df.loc[:, TEMPORAL_FEATURES] = scaler_temporal.transform(df[TEMPORAL_FEATURES])\n","/tmp/ipython-input-3970574989.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.19555716 -0.19555716 -0.19555716 ... -0.19555716 -0.19555716\n"," -0.19555716]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.loc[:, TEMPORAL_FEATURES] = scaler_temporal.transform(df[TEMPORAL_FEATURES])\n"]},{"output_type":"stream","name":"stdout","text":["Sequences -> train: 93129, val: 20307 | min_len: 4\n","Train label distribution: [26478, 33042, 33609]\n"]}],"source":["# Làm sạch dữ liệu\n","from sklearn.preprocessing import StandardScaler\n","\n","# Parse time + map tr_status -> numeric\n","df[TIME_COL] = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n","df[\"tr_status_num\"] = df[\"tr_status\"].map({\"passed\": 0, \"failed\": 1}).fillna(-1).astype(int)\n","\n","used_cols = (\n","    TEMPORAL_FEATURES\n","    + STATIC_FEATURES\n","    + [LABEL_COL, GROUP_COL, TIME_COL, \"tr_build_number\", BUILD_ID_COL, PREV_BUILD_COL]\n",")\n","df = df[used_cols].copy()\n","\n","df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors=\"coerce\")\n","df = df.dropna(subset=[LABEL_COL]).reset_index(drop=True)\n","df[LABEL_COL] = df[LABEL_COL].astype(int)\n","\n","for col in TEMPORAL_FEATURES + STATIC_FEATURES:\n","    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n","\n","df[BUILD_ID_COL] = pd.to_numeric(df[BUILD_ID_COL], errors=\"coerce\").fillna(-1).astype(\"int64\")\n","df[PREV_BUILD_COL] = pd.to_numeric(df[PREV_BUILD_COL], errors=\"coerce\").fillna(-1).astype(\"int64\")\n","\n","sort_cols = [GROUP_COL, TIME_COL]\n","if \"tr_build_number\" in df.columns:\n","    sort_cols.append(\"tr_build_number\")\n","df = df.sort_values(sort_cols).reset_index(drop=True)\n","\n","def split_by_repo_time_indices(df, group_col=GROUP_COL, val_ratio=0.2):\n","    train_idx = []\n","    val_idx = []\n","    for _, g in df.groupby(group_col, sort=False):\n","        cut = int(len(g) * (1 - val_ratio))\n","        train_idx.extend(g.index[:cut])\n","        val_idx.extend(g.index[cut:])\n","    return train_idx, val_idx\n","\n","train_indices, val_indices = split_by_repo_time_indices(df)\n","train_df = df.loc[train_indices]\n","\n","for col in TEMPORAL_FEATURES + STATIC_FEATURES:\n","    if df[col].isna().sum() > 0:\n","        if train_df[col].nunique(dropna=True) <= 2:\n","            fill_value = train_df[col].mode(dropna=True).iloc[0]\n","        else:\n","            fill_value = train_df[col].median()\n","        df[col] = df[col].fillna(fill_value)\n","\n","LOG1P_FEATURES = [c for c in LOG1P_FEATURES if c in df.columns]\n","for col in LOG1P_FEATURES:\n","    df[col] = np.log1p(df[col].clip(lower=0))\n","\n","train_df = df.loc[train_indices]\n","\n","def drop_constant(features, ref_df):\n","    return [c for c in features if ref_df[c].nunique(dropna=False) > 1]\n","\n","TEMPORAL_FEATURES = drop_constant(TEMPORAL_FEATURES, train_df)\n","STATIC_FEATURES = drop_constant(STATIC_FEATURES, train_df)\n","LOG1P_FEATURES = [c for c in LOG1P_FEATURES if c in TEMPORAL_FEATURES + STATIC_FEATURES]\n","\n","scaler_static = StandardScaler()\n","scaler_temporal = StandardScaler()\n","\n","scaler_static.fit(train_df[STATIC_FEATURES])\n","scaler_temporal.fit(train_df[TEMPORAL_FEATURES])\n","\n","df.loc[:, STATIC_FEATURES] = scaler_static.transform(df[STATIC_FEATURES])\n","df.loc[:, TEMPORAL_FEATURES] = scaler_temporal.transform(df[TEMPORAL_FEATURES])\n","\n","\n","# Tạo Dataset cho Bayesian LSTM\n","from torch.utils.data import DataLoader\n","\n","SEQ_LEN = 10\n","MIN_SEQ_LEN = 4\n","BATCH_SIZE = 256\n","PIN_MEMORY = torch.cuda.is_available()\n","\n","all_sequences = build_sequences_from_prev(df, SEQ_LEN, MIN_SEQ_LEN)\n","train_index_set = set(train_indices)\n","val_index_set = set(val_indices)\n","train_sequences = [s for s in all_sequences if s[1] in train_index_set]\n","val_sequences = [s for s in all_sequences if s[1] in val_index_set]\n","\n","train_dataset = BuildSequenceDataset(df, train_sequences)\n","val_dataset = BuildSequenceDataset(df, val_sequences)\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=0,\n","    pin_memory=PIN_MEMORY\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    pin_memory=PIN_MEMORY\n",")\n","\n","num_classes = int(df[LABEL_COL].max()) + 1\n","train_labels = np.array(\n","    [int(df.iloc[label_idx][LABEL_COL]) for _, label_idx, _ in train_sequences],\n","    dtype=np.int64\n",")\n","class_counts = np.bincount(train_labels, minlength=num_classes)\n","total_count = class_counts.sum()\n","class_weights = np.zeros(num_classes, dtype=np.float32)\n","nonzero = class_counts > 0\n","class_weights[nonzero] = total_count / (num_classes * class_counts[nonzero])\n","\n","print(\n","    f\"Sequences -> train: {len(train_sequences)}, val: {len(val_sequences)} \"\n","    f\"| min_len: {MIN_SEQ_LEN}\"\n",")\n","print(f\"Train label distribution: {class_counts.tolist()}\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xHFUnjTtFird","executionInfo":{"status":"ok","timestamp":1767254417517,"user_tz":-420,"elapsed":5,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[],"source":["# Xây dựng kiến trúc model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","\n","LSTM_HIDDEN_DIM = 96\n","LSTM_LAYERS = 2\n","LSTM_DROPOUT = 0.2\n","TEMPORAL_DROPOUT = 0.2\n","LABEL_SMOOTHING = 0.03\n","\n","class BayesianLSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers=1, dropout=0.0, temporal_dropout=0.0):\n","        super().__init__()\n","        self.lstm = nn.LSTM(\n","            input_dim,\n","            hidden_dim,\n","            batch_first=True,\n","            num_layers=num_layers,\n","            dropout=dropout if num_layers > 1 else 0.0\n","        )\n","        self.attn = nn.Linear(hidden_dim, 1)\n","        self.temporal_dropout = nn.Dropout(temporal_dropout)\n","\n","    def forward(self, x, lengths):\n","        lengths_cpu = lengths.to(\"cpu\")\n","        packed = nn.utils.rnn.pack_padded_sequence(\n","            x,\n","            lengths_cpu,\n","            batch_first=True,\n","            enforce_sorted=False\n","        )\n","        packed_out, _ = self.lstm(packed)\n","        h, _ = nn.utils.rnn.pad_packed_sequence(\n","            packed_out,\n","            batch_first=True,\n","            total_length=x.size(1)\n","        )\n","\n","        max_len = h.size(1)\n","        mask = torch.arange(max_len, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(1)\n","        attn_scores = self.attn(h).squeeze(-1)\n","        attn_scores = attn_scores.masked_fill(~mask, -1e9)\n","        weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1)\n","        context = (weights * h).sum(dim=1)\n","        return self.temporal_dropout(context)\n","\n","# Bayesian MLP (Static branch)\n","class BayesianMLP(nn.Module):\n","  def __init__(self, input_dim):\n","      super().__init__()\n","      self.net = nn.Sequential(\n","          nn.Linear(input_dim, 128),\n","          nn.ReLU(),\n","          nn.Dropout(0.4),\n","          nn.Linear(128, 64),\n","          nn.ReLU(),\n","          nn.Dropout(0.4)\n","      )\n","\n","  def forward(self, x):\n","      return self.net(x)\n","\n","class BayesianRiskModel(nn.Module):\n","    def __init__(self, temporal_dim, static_dim):\n","        super().__init__()\n","\n","        self.temporal = BayesianLSTM(\n","            temporal_dim,\n","            LSTM_HIDDEN_DIM,\n","            num_layers=LSTM_LAYERS,\n","            dropout=LSTM_DROPOUT,\n","            temporal_dropout=TEMPORAL_DROPOUT\n","        )\n","        self.static = BayesianMLP(static_dim)\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(LSTM_HIDDEN_DIM + 64, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, 3)\n","        )\n","\n","    def forward(self, seq, static, lengths):\n","        t = self.temporal(seq, lengths)\n","        s = self.static(static)\n","        x = torch.cat([t, s], dim=1)\n","        return self.classifier(x)\n","\n","model = BayesianRiskModel(\n","    temporal_dim=len(TEMPORAL_FEATURES),\n","    static_dim=len(STATIC_FEATURES)\n",")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n","\n","LR = 1e-3\n","WEIGHT_DECAY = 1e-4\n","EPOCHS = 20\n","EARLY_STOP_PATIENCE = 5\n","MIN_DELTA = 1e-4\n","GRAD_CLIP_NORM = 1.0\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n","criterion = nn.CrossEntropyLoss(\n","    weight=class_weights_tensor,\n","    label_smoothing=LABEL_SMOOTHING\n",")\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,\n","    mode=\"max\",\n","    factor=0.5,\n","    patience=2,\n","    min_lr=1e-5\n",")\n","\n","def evaluate(model, data_loader, criterion, device, num_classes):\n","    model.eval()\n","    total_loss = 0.0\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for seq, static, label, lengths in data_loader:\n","            seq = seq.to(device)\n","            static = static.to(device)\n","            label = label.to(device)\n","            lengths = lengths.to(device)\n","\n","            logits = model(seq, static, lengths)\n","            loss = criterion(logits, label)\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=1)\n","            all_labels.append(label.cpu().numpy())\n","            all_preds.append(preds.cpu().numpy())\n","\n","    avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else 0.0\n","    if all_labels:\n","        y_true = np.concatenate(all_labels)\n","        y_pred = np.concatenate(all_preds)\n","        acc = accuracy_score(y_true, y_pred)\n","        f1 = f1_score(y_true, y_pred, average=\"macro\")\n","        cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n","    else:\n","        acc = 0.0\n","        f1 = 0.0\n","        cm = np.zeros((num_classes, num_classes), dtype=int)\n","\n","    return avg_loss, acc, f1, cm\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a3-rt4vFjui","outputId":"e87d0096-aa5c-43da-b141-5bf947296f1f","executionInfo":{"status":"ok","timestamp":1767256302148,"user_tz":-420,"elapsed":1884631,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","[Epoch 1] Train Loss: 0.6896 | Val Loss: 0.5882 | Val Acc: 0.7818 | Val F1(macro): 0.7777 | LR: 1.00e-03\n","[Epoch 2] Train Loss: 0.5183 | Val Loss: 0.5637 | Val Acc: 0.7967 | Val F1(macro): 0.7911 | LR: 1.00e-03\n","[Epoch 3] Train Loss: 0.4569 | Val Loss: 0.5893 | Val Acc: 0.8193 | Val F1(macro): 0.8138 | LR: 1.00e-03\n","[Epoch 4] Train Loss: 0.4261 | Val Loss: 0.6310 | Val Acc: 0.8059 | Val F1(macro): 0.8033 | LR: 1.00e-03\n","[Epoch 5] Train Loss: 0.4013 | Val Loss: 0.5955 | Val Acc: 0.8045 | Val F1(macro): 0.7998 | LR: 1.00e-03\n","[Epoch 6] Train Loss: 0.3842 | Val Loss: 0.5987 | Val Acc: 0.8200 | Val F1(macro): 0.8188 | LR: 1.00e-03\n","[Epoch 7] Train Loss: 0.3683 | Val Loss: 0.5856 | Val Acc: 0.8056 | Val F1(macro): 0.8038 | LR: 1.00e-03\n","[Epoch 8] Train Loss: 0.3577 | Val Loss: 0.6224 | Val Acc: 0.8115 | Val F1(macro): 0.8127 | LR: 1.00e-03\n","[Epoch 9] Train Loss: 0.3489 | Val Loss: 0.6021 | Val Acc: 0.7992 | Val F1(macro): 0.7967 | LR: 5.00e-04\n","[Epoch 10] Train Loss: 0.3354 | Val Loss: 0.5819 | Val Acc: 0.8100 | Val F1(macro): 0.8135 | LR: 5.00e-04\n","[Epoch 11] Train Loss: 0.3276 | Val Loss: 0.5832 | Val Acc: 0.8130 | Val F1(macro): 0.8168 | LR: 5.00e-04\n","Early stopping at epoch 11\n","Best epoch: 6 | Val Loss: 0.5987 | Val Acc: 0.8200 | Val F1(macro): 0.8188\n","Confusion matrix (val):\n","[[3533  892   47]\n"," [ 500 5664  662]\n"," [  21 1533 7455]]\n","✅ Training completed! Latest checkpoint: /content/drive/MyDrive/build-risk/checkpoints/ckpt_latest.pt\n","✅ Best checkpoint: /content/drive/MyDrive/build-risk/checkpoints/ckpt_best.pt\n"]}],"source":["# Training loop + checkpoint (Colab)\n","import copy\n","import os\n","\n","CHECKPOINT_DIR = \"/content/drive/MyDrive/build-risk/checkpoints\"\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n","CKPT_PATH = os.path.join(CHECKPOINT_DIR, \"ckpt_latest.pt\")\n","CKPT_BEST_PATH = os.path.join(CHECKPOINT_DIR, \"ckpt_best.pt\")\n","\n","print(f\"Using device: {device}\")\n","\n","start_epoch = 0\n","best_f1 = -1.0\n","best_state = None\n","best_epoch = -1\n","patience_counter = 0\n","\n","if os.path.exists(CKPT_PATH):\n","    ckpt = torch.load(CKPT_PATH, map_location=device)\n","    try:\n","        model.load_state_dict(ckpt[\"model_state_dict\"])\n","        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n","        start_epoch = ckpt.get(\"epoch\", -1) + 1\n","        best_f1 = ckpt.get(\"best_f1\", -1.0)\n","        best_epoch = ckpt.get(\"best_epoch\", -1)\n","        print(f\"✅ Resume from epoch {start_epoch}\")\n","    except RuntimeError as exc:\n","        print(\"⚠️ Checkpoint không tương thích, train lại từ đầu.\")\n","        print(exc)\n","        start_epoch = 0\n","        best_f1 = -1.0\n","        best_epoch = -1\n","\n","for epoch in range(start_epoch, EPOCHS):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for seq, static, label, lengths in train_loader:\n","        seq = seq.to(device)\n","        static = static.to(device)\n","        label = label.to(device)\n","        lengths = lengths.to(device)\n","\n","        optimizer.zero_grad()\n","        logits = model(seq, static, lengths)\n","        loss = criterion(logits, label)\n","        loss.backward()\n","        if GRAD_CLIP_NORM is not None:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_train_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0.0\n","    val_loss, val_acc, val_f1, val_cm = evaluate(\n","        model, val_loader, criterion, device, num_classes\n","    )\n","    scheduler.step(val_f1)\n","    current_lr = optimizer.param_groups[0][\"lr\"]\n","\n","    print(\n","        f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | \"\n","        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n","        f\"Val F1(macro): {val_f1:.4f} | LR: {current_lr:.2e}\"\n","    )\n","\n","    torch.save({\n","        \"epoch\": epoch,\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"temporal_dim\": len(TEMPORAL_FEATURES),\n","        \"static_dim\": len(STATIC_FEATURES),\n","        \"temporal_features\": TEMPORAL_FEATURES,\n","        \"static_features\": STATIC_FEATURES,\n","        \"log1p_features\": LOG1P_FEATURES,\n","        \"seq_len\": SEQ_LEN,\n","        \"min_seq_len\": MIN_SEQ_LEN,\n","        \"lstm_hidden_dim\": LSTM_HIDDEN_DIM,\n","        \"lstm_layers\": LSTM_LAYERS,\n","        \"lstm_dropout\": LSTM_DROPOUT,\n","        \"temporal_dropout\": TEMPORAL_DROPOUT,\n","        \"label_smoothing\": LABEL_SMOOTHING,\n","        \"best_f1\": best_f1,\n","        \"best_epoch\": best_epoch\n","    }, CKPT_PATH)\n","\n","    if val_f1 > best_f1 + MIN_DELTA:\n","        best_f1 = val_f1\n","        best_state = copy.deepcopy(model.state_dict())\n","        best_epoch = epoch\n","        patience_counter = 0\n","\n","        torch.save({\n","            \"epoch\": epoch,\n","            \"model_state_dict\": model.state_dict(),\n","            \"optimizer_state_dict\": optimizer.state_dict(),\n","            \"temporal_dim\": len(TEMPORAL_FEATURES),\n","            \"static_dim\": len(STATIC_FEATURES),\n","            \"temporal_features\": TEMPORAL_FEATURES,\n","            \"static_features\": STATIC_FEATURES,\n","            \"log1p_features\": LOG1P_FEATURES,\n","            \"seq_len\": SEQ_LEN,\n","            \"min_seq_len\": MIN_SEQ_LEN,\n","            \"lstm_hidden_dim\": LSTM_HIDDEN_DIM,\n","            \"lstm_layers\": LSTM_LAYERS,\n","            \"lstm_dropout\": LSTM_DROPOUT,\n","            \"temporal_dropout\": TEMPORAL_DROPOUT,\n","            \"label_smoothing\": LABEL_SMOOTHING,\n","            \"val_f1_macro\": val_f1\n","        }, CKPT_BEST_PATH)\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= EARLY_STOP_PATIENCE:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n","\n","if best_state is not None:\n","    model.load_state_dict(best_state)\n","    final_val_loss, final_val_acc, final_val_f1, final_val_cm = evaluate(\n","        model, val_loader, criterion, device, num_classes\n","    )\n","    print(\n","        f\"Best epoch: {best_epoch + 1} | \"\n","        f\"Val Loss: {final_val_loss:.4f} | Val Acc: {final_val_acc:.4f} | \"\n","        f\"Val F1(macro): {final_val_f1:.4f}\"\n","    )\n","    print(\"Confusion matrix (val):\")\n","    print(final_val_cm)\n","\n","print(f\"✅ Training completed! Latest checkpoint: {CKPT_PATH}\")\n","if best_state is not None:\n","    print(f\"✅ Best checkpoint: {CKPT_BEST_PATH}\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUmrZpO1bRKS","outputId":"b2ed2751-449d-461a-c4f8-29e2aa8dc7c4","executionInfo":{"status":"ok","timestamp":1767256303549,"user_tz":-420,"elapsed":1386,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model saved to: ./artifacts/bayesian_risk_model.pt\n","✅ Scaler static saved to: ./artifacts/scaler_static.pkl\n","✅ Scaler temporal saved to: ./artifacts/scaler_temporal.pkl\n"]}],"source":["# Export model + scalers\n","import torch\n","import joblib\n","import os\n","\n","SAVE_DIR = \"./artifacts\"\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","MODEL_PATH = f\"{SAVE_DIR}/bayesian_risk_model.pt\"\n","SCALER_STATIC_PATH = f\"{SAVE_DIR}/scaler_static.pkl\"\n","SCALER_TEMPORAL_PATH = f\"{SAVE_DIR}/scaler_temporal.pkl\"\n","\n","# Save model\n","torch.save({\n","    \"model_state_dict\": model.state_dict(),\n","    \"temporal_dim\": len(TEMPORAL_FEATURES),\n","    \"static_dim\": len(STATIC_FEATURES),\n","    \"temporal_features\": TEMPORAL_FEATURES,\n","    \"static_features\": STATIC_FEATURES,\n","    \"log1p_features\": LOG1P_FEATURES,\n","    \"seq_len\": SEQ_LEN,\n","    \"min_seq_len\": MIN_SEQ_LEN,\n","    \"lstm_hidden_dim\": LSTM_HIDDEN_DIM,\n","    \"lstm_layers\": LSTM_LAYERS,\n","    \"lstm_dropout\": LSTM_DROPOUT,\n","    \"temporal_dropout\": TEMPORAL_DROPOUT,\n","    \"label_smoothing\": LABEL_SMOOTHING\n","}, MODEL_PATH)\n","\n","# Save scalers\n","joblib.dump(scaler_static, SCALER_STATIC_PATH)\n","joblib.dump(scaler_temporal, SCALER_TEMPORAL_PATH)\n","\n","print(f\"✅ Model saved to: {MODEL_PATH}\")\n","print(f\"✅ Scaler static saved to: {SCALER_STATIC_PATH}\")\n","print(f\"✅ Scaler temporal saved to: {SCALER_TEMPORAL_PATH}\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_tzID6HFj0D","outputId":"1c67463b-8d7c-4cd3-9db2-ef840153f458","executionInfo":{"status":"ok","timestamp":1767258424637,"user_tz":-420,"elapsed":2014,"user":{"displayName":"Lai THung","userId":"03033634996041571217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Testing MC Dropout Inference...\n","Batch size: 256\n","Mean Prob (first 5):\n","[[0.89940256 0.08722179 0.01337562]\n"," [0.8822334  0.10367239 0.01409432]\n"," [0.9188653  0.06687705 0.01425752]\n"," [0.88936406 0.09769483 0.01294132]\n"," [0.8940732  0.09504213 0.01088479]]\n","Uncertainty (first 5): [0.00266975 0.0038117  0.00230808 0.00540886 0.00242972]\n"]}],"source":["# Hàm inference Bayesian + Validation\n","import numpy as np\n","\n","def mc_dropout_predict(model, seq, static, lengths, n_samples=30):\n","    model.train()  # quan trọng: bật dropout\n","\n","    probs = []\n","    for _ in range(n_samples):\n","        logits = model(seq, static, lengths)\n","        probs.append(torch.softmax(logits, dim=1).detach().cpu().numpy())\n","\n","    probs = np.stack(probs)\n","    mean_prob = probs.mean(axis=0)\n","    uncertainty = probs.var(axis=0).mean(axis=1)\n","\n","    return mean_prob, uncertainty\n","\n","# Validation + Uncertainty\n","model.eval()\n","\n","print(\"Testing MC Dropout Inference...\")\n","with torch.no_grad():\n","    seq, static, label, lengths = next(iter(val_loader))\n","    seq = seq.to(device)\n","    static = static.to(device)\n","    lengths = lengths.to(device)\n","\n","    mean_prob, uncertainty = mc_dropout_predict(\n","        model, seq, static, lengths, n_samples=30\n","    )\n","\n","    # Sửa lại đoạn in kết quả\n","    print(f\"Batch size: {len(mean_prob)}\")\n","    print(f\"Mean Prob (first 5):\\n{mean_prob[:5]}\")\n","    print(f\"Uncertainty (first 5): {uncertainty[:5]}\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"}},"nbformat":4,"nbformat_minor":0}