# âš¡ FLOW 1 Quick Reference Card

## ğŸ¯ Flow Overview

**Luá»“ng 1: Import Repos tá»« GitHub & Extract Features**

- **Actors**: Developer, System
- **Duration**: 10-60 minutes (+ feature extraction)
- **Status Progression**: QUEUED â†’ IMPORTING â†’ IMPORTED â†’ FAILED

---

## ğŸ“Š 3 Phases

### Phase 1ï¸âƒ£: Search & Configure (< 5 sec)
```
UI â†’ API â†’ GitHub API â†’ Return results â†’ Display â†’ Select & Configure
```

### Phase 2ï¸âƒ£: Import (10-60 min)
```
import_repo â†’ clone_repo â†’ fetch_and_save_builds â†’ dispatch_processing
    â†“           â†“              â†“                        â†“
  Queue      Git ops        CI fetch               Task schedule
```

### Phase 3ï¸âƒ£: Extract Features (1-5 min per build, parallel)
```
process_workflow_run (per build)
  â”œâ”€ build_hamilton_inputs()
  â”œâ”€ HamiltonPipeline.run()
  â”‚  â”œâ”€ build_features
  â”‚  â”œâ”€ git_features
  â”‚  â”œâ”€ github_features
  â”‚  â”œâ”€ repo_features
  â”‚  â””â”€ log_features
  â””â”€ Save to DB
```

---

## ğŸŠ 5 Swimlanes

| # | Swimlane | Color | Role |
|----|----------|-------|------|
| 1 | **UI / Frontend** | ğŸ”µ #E1F5FE | User interactions, WebSocket listener |
| 2 | **API Layer** | ğŸŸ£ #F3E5F5 | REST endpoints, validation, DB ops |
| 3 | **Celery Tasks** | ğŸŸ¢ #E8F5E9 | Async orchestration, processing |
| 4 | **Database** | ğŸŸ  #FFF3E0 | MongoDB CRUD operations |
| 5 | **External** | ğŸ”´ #FCE4EC | GitHub API, Git ops, CI providers |

---

## 9ï¸âƒ£ Use Cases

```
UC1: Search GitHub Repos          â†’ Find repos on GitHub
UC2: Select Repositories          â†’ Multi-select from results
UC3: Configure Import Settings    â†’ Set frameworks, languages, limits
UC4: Import Repositories          â†’ Trigger import
UC5: Clone Repository             â†’ Git clone --bare
UC6: Fetch Builds from CI         â†’ Get builds from GitHub Actions/Travis
UC7: Extract Features             â†’ Hamilton DAG feature extraction
UC8: View Import Progress         â†’ Real-time WebSocket updates
UC9: View Build Metrics           â†’ Display extracted features
```

---

## ğŸ“Š Database Entities

```
RawRepository
  â”œâ”€ full_name, github_repo_id, default_branch
  â””â”€ is_private, main_lang, github_metadata

ModelRepoConfig (User's config)
  â”œâ”€ raw_repo_id â†’ RawRepository
  â”œâ”€ test_frameworks, source_languages
  â”œâ”€ ci_provider, import_status
  â””â”€ max_builds, since_days, only_with_logs

RawBuildRun
  â”œâ”€ build_id, build_number, branch, commit_sha
  â”œâ”€ status, conclusion, logs_available
  â””â”€ raw_data, provider

ModelTrainingBuild (With features)
  â”œâ”€ raw_workflow_run_id â†’ RawBuildRun
  â”œâ”€ extraction_status (PENDING â†’ COMPLETED)
  â”œâ”€ features {} (extracted data)
  â””â”€ build_conclusion, error_message
```

---

## ğŸ”— API Endpoints

```
GET  /repos/search?q=<query>
     â†’ Returns: {private_matches[], public_matches[]}

POST /repos/import/bulk
     â† Payload: [{full_name, installation_id, test_frameworks, ...}]
     â†’ Returns: RepoResponse[] {status: QUEUED}

GET  /repos/languages?full_name=owner/repo
     â†’ Returns: [detected languages]

GET  /repos/test-frameworks
     â†’ Returns: {frameworks[], by_language{}, languages[]}
```

---

## ğŸ”„ Celery Task Chain

```
import_repo(repo_id, full_name, installation_id, ci_provider, ...)
  â”‚
  â”œâ”€â†’ clone_repo.s(repo_id, full_name, installation_id)
  â”‚   â”‚
  â”‚   â”œâ”€ git fetch --all --prune (if exists)
  â”‚   â””â”€ git clone --bare URL (if new)
  â”‚
  â”œâ”€â†’ fetch_and_save_builds.s(repo_id, full_name, ci_provider, ...)
  â”‚   â”‚
  â”‚   â”œâ”€ ci_instance.fetch_builds(...)
  â”‚   â””â”€ for each build: Create RawBuildRun + ModelTrainingBuild
  â”‚
  â””â”€â†’ dispatch_processing.s(repo_id)
      â”‚
      â””â”€ for batch in build_ids (50 per batch):
         â””â”€ group([process_workflow_run.s(...) for each build])
```

---

## ğŸ’¾ Hamilton DAG Features

### 5 Extractors

1. **build_features** - Test results, build time, failures
2. **git_features** - Commit history, branching patterns
3. **github_features** - PR reviews, issue statistics
4. **repo_features** - Repository metadata, size
5. **log_features** - Test log analysis, compiler output

### Feature Examples
```
build_features:     tr_build_duration, tr_test_count, tr_test_failed
git_features:       g_num_commits, g_num_authors, gi_num_large_files
github_features:    gh_pr_review_count, gh_issue_count
repo_features:      r_lines_of_code, r_num_files
log_features:       log_test_error_count, log_warning_count
```

---

## ğŸ”Œ WebSocket Events

```
REPO_UPDATE
{
  "type": "REPO_UPDATE",
  "payload": {
    "repo_id": "...",
    "status": "importing|cloned|imported|failed",
    "message": "..."
  }
}

BUILD_UPDATE
{
  "type": "BUILD_UPDATE",
  "payload": {
    "repo_id": "...",
    "build_id": "...",
    "status": "in_progress|completed|failed"
  }
}
```

---

## âš™ï¸ Configuration Options

```
test_frameworks:      ["pytest", "junit", ...]
source_languages:     ["python", "java", ...]
ci_provider:          "github_actions" (or travis, jenkins)
max_builds:           1-1000 (default: 100)
since_days:           1-3650 (default: 180 days)
only_with_logs:       true/false (default: true)
```

---

## ğŸ“ˆ Timeline

```
T+0s:    User clicks Import
T+0-60s: Phase 1 (Search & Config) [UI]
T+60s:   import_repo queued
T+1m:    Phase 2 starts (Import) [Async]
T+5-30m: clone_repo
T+10-40m: fetch_and_save_builds
T+40m:   dispatch_processing
T+45m:   Phase 3 starts (Feature Extraction) [Parallel]
T+45-90m: process_workflow_run (50-100 builds)
T+90m:   Complete!
```

---

## âœ… Files Generated

```
âœ… flow1_use_case.puml
   â””â”€ 2 actors, 9 use cases, associations

âœ… flow1_activity_swimlanes.puml
   â””â”€ 5 swimlanes, 3 phases, 40+ activities

âœ… flow1_sequence_diagram.puml
   â””â”€ 6 participants, 6 sequence phases

ğŸ“„ FLOW1_COMPLETE_DOCUMENTATION.md
   â””â”€ Comprehensive reference (architecture, API, DB, performance)

ğŸ“„ FLOW1_DETAILED_GUIDE.md
   â””â”€ Use cases, swimlanes, phases, API flows

ğŸ“„ ASTAH_STEP_BY_STEP_GUIDE.md
   â””â”€ How to create diagrams in Astah UML

ğŸ“„ FLOW1_DIAGRAM_INDEX.md
   â””â”€ Document index and navigation
```

---

## ğŸš€ Next Steps

1. **View PlantUML**: Open `.puml` files at https://www.plantuml.com/plantuml/uml/
2. **Create in Astah**: Follow `ASTAH_STEP_BY_STEP_GUIDE.md`
3. **Export Diagrams**: SVG/PNG for thesis
4. **Update Thesis**: Include diagrams in appropriate sections
5. **Present**: Show to advisor with complete documentation

---

## ğŸ’¡ Key Insights

âœ¨ **Asynchronous**: All heavy operations run via Celery  
âœ¨ **Real-time**: WebSocket updates keep UI synchronized  
âœ¨ **Scalable**: Batch processing and parallelization  
âœ¨ **Resilient**: Error handling and retry logic  
âœ¨ **Flexible**: Customizable frameworks, languages, CI providers  
âœ¨ **Modular**: 5 separate feature extractors (Hamilton DAG)

---

**Status**: âœ… Ready for Astah Import  
**Last Update**: 2025-12-14

